{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FeedForward_Network as fn\n",
    "import forward_propagation as fp\n",
    "import backward_propagation as bp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import mnist\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "np.random.seed(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save parameters\n",
    "def save_pickle(a,filename):\n",
    "    with open(filename+'.pickle', 'wb') as handle:\n",
    "        pickle.dump(a, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#load parameters\n",
    "def load_pickle(filename):\n",
    "    with open(filename+'.pickle', 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "        return b\n",
    "\n",
    "#save logs file\n",
    "def writeToFile(stat, text, filename):\n",
    "    if stat == 0:\n",
    "        file = open('logs/'+filename+'_log_file.txt', \"w\")\n",
    "        file.write(\"***** log file start *****\" +str(datetime.datetime.now()) +\"\\n\")\n",
    "        file.write(text + \"\\n\")\n",
    "    if stat == 1:\n",
    "        file = open('logs/'+filename+'_log_file.txt', \"a\")\n",
    "        file.write(text + '\\n')\n",
    "    file.flush()\n",
    "    file.close()\n",
    "\n",
    "#list to string    \n",
    "def textargs(*args):\n",
    "    text=','.join([str(arg) for arg in args])\n",
    "    return text\n",
    "\n",
    "#batch size **2\n",
    "def batch_list(x=64,maxb=1024):\n",
    "    li=[]\n",
    "    while x<= 1024:\n",
    "        li.append(x)\n",
    "        x *= 2        \n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "#  load small data\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/seeds_norm.csv')\n",
    "data=data.sample(frac=1)\n",
    "x_train = data.iloc[:,:-1].values\n",
    "y_train = data.iloc[:,-1].values\n",
    "\n",
    "y_train=y_train-1\n",
    "\n",
    "nb_classes = 3\n",
    "targets = y_train.reshape(-1)\n",
    "y_train = np.eye(nb_classes)[targets]\n",
    "layers_dims = [7, 20, 10, 5 , 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameters=None\n",
    "for i in range(5):\n",
    "    parameters,cost=fn.L_layer_model(x_train.T, y_train, layers_dims, 0.009, num_iterations = 100,batch_size=4,param=parameters,use_batchnorm=1,dropout_keep_prob=1)\n",
    "    print(fn.predict(x_train,y_train,parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# load mnist data\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float64')\n",
    "x_test = x_test.astype('float64')\n",
    "\n",
    "#y one hot\n",
    "nb_classes = 10\n",
    "targets = y_train.reshape(-1)\n",
    "y_train = np.eye(nb_classes)[targets]\n",
    "\n",
    "targets_test = y_test.reshape(-1)\n",
    "y_test = np.eye(nb_classes)[targets_test]\n",
    "\n",
    "#norm\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "#flat\n",
    "height , weight = x_train.shape[1:]\n",
    "image_vector_size= height * weight\n",
    "x_train = x_train.reshape(x_train.shape[0], image_vector_size)\n",
    "x_test = x_test.reshape(x_test.shape[0], image_vector_size)\n",
    "\n",
    "#train validation\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "#layers of net\n",
    "layers_dims = [784, 20, 7, 5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# test run for model\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters=None\n",
    "for i in range(10):\n",
    "    print('\\n')\n",
    "    print('cost')\n",
    "    parameters,cost=fn.L_layer_model(x_train.T, y_train, layers_dims, 0.009, num_iterations = 100,batch_size=1000,param=parameters,use_batchnorm=0,dropout_keep_prob=0.7)\n",
    "    print('train')\n",
    "    fn.predict(x_train,y_train,parameters)\n",
    "    print('valid')\n",
    "    fn.predict(x_valid,y_valid,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# running tests dropout and batch size\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for drop_keep in np.arange(0.6,1,0.05):\n",
    "    for batch_size in batch_list():\n",
    "        \n",
    "        acc_train_list=[]\n",
    "        acc_valid_list=[]\n",
    "        acc_test_list=[]\n",
    "        costs=[]\n",
    "        \n",
    "        eps=1e-10\n",
    "        acc_last=0\n",
    "        num=1\n",
    "        iterations=100\n",
    "        epochs=0\n",
    "\n",
    "        improve=True\n",
    "        save_param=True\n",
    "        parameters=None\n",
    "    \n",
    "        t=time.time()\n",
    "        batch_drop='dr_'+str(round(drop_keep,2))+'_bs_'+str(batch_size)+'_'\n",
    "        writeToFile(0,'acc_train,acc_valid,acc_test,cost,runtime,epochs,batch_size,timestamp',batch_drop)\n",
    "        while improve:\n",
    "        \n",
    "            parameters,cost = fn.L_layer_model(x_train.T, y_train, layers_dims, 0.009, num_iterations = iterations,batch_size=batch_size,use_batchnorm=True,param=parameters,dropout_keep_prob=drop_keep)\n",
    "            costs.append(cost[-1])\n",
    "            \n",
    "            acc_train=fn.predict(x_train,y_train,parameters)\n",
    "            acc_valid = fn.predict(x_valid,y_valid,parameters)\n",
    "            acc_test = fn.predict(x_test,y_test,parameters)\n",
    "            \n",
    "            if acc_last > acc_valid or acc_valid - acc_last < eps:\n",
    "                improve=False\n",
    "                save_param=False\n",
    "            \n",
    "            acc_last=acc_valid\n",
    "            epochs=num*iterations\n",
    "            runtime=time.time()-t\n",
    "            writeToFile(1,textargs(acc_train,acc_valid,acc_test,cost[-1],runtime,epochs,batch_size,str(datetime.datetime.now())),batch_drop)\n",
    "            \n",
    "            if save_param:\n",
    "                now = datetime.datetime.now()\n",
    "                pick_time='models/ep'+str(epochs)+'__bs'+str(batch_size)+'__dr'+str(round(drop_keep,2))+'_'+str(now.strftime(\"%Y-%m-%d_%H_%M_%S\"))\n",
    "                save_pickle(parameters,pick_time)\n",
    "            print('epochs: ',epochs)\n",
    "            num+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
